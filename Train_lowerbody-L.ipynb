{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "df266d2b-0f34-4579-80a8-398a68e652b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b02a96a-bb28-4939-8b57-cec35a1c6ab5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow-gpu==2.3\n",
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed352fe7-1d49-4531-b5df-1d7b4fae3386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc834e16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7dbb8e82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f505bea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 16495416793614196120]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd72a9c2-68ef-469d-ab07-cf21f7b2f842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4115, 30, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actions = [\n",
    "    'assult',\n",
    "    'nomal',\n",
    "    ]\n",
    "\n",
    "file_dir = 'C:/Users/chltp/detect_video/dataset/'#seq 파일을 dataset 폴더에 넣어주세요\n",
    "\n",
    "npy_file = []\n",
    "for name in os.listdir(file_dir):\n",
    "    if not len(np.load(file_dir + name)) == 0:\n",
    "        npy_file.append(np.load(file_dir + name))\n",
    "\n",
    "data = np.concatenate(npy_file, axis=0)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1ffbc0b4-6ba3-49ca-90a1-3a9afa3125a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4115, 30, 3)\n",
      "(4115,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3ead60ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4115):\n",
    "    for j in range(29):\n",
    "        if x_data[i][j][2]==7 or x_data[i][j][2]==9 or x_data[i][j][2]==11:\n",
    "            x_data[i][j][2]=1\n",
    "        else: x_data[i][j][2]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bfbcef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # punching = []\n",
    "# # kicking = []\n",
    "# # normal = []\n",
    "\n",
    "# slap_L = []\n",
    "# slap_R = []\n",
    "# pushing_A = []\n",
    "# pushing_L = []\n",
    "# pushing_R = []\n",
    "# punching_L = []\n",
    "# puncning_R = []\n",
    "# kicking_L = []\n",
    "# kicking_R = []\n",
    "# tread_L = []\n",
    "# tread_R = []\n",
    "# footpushing_L = []\n",
    "# footpushing_R = []\n",
    "# normal = []\n",
    "\n",
    "# count = 0\n",
    "# for count in range(len(x_data)):\n",
    "#     temp_count = 0\n",
    "#     temp = 0\n",
    "#     for j in range(30):\n",
    "#         for i in range(54, 66):\n",
    "#             t = data[count][j][i]\n",
    "#     #         print(t)\n",
    "#             if t != 0 and not np.isnan(t):\n",
    "#                 temp += int(t)\n",
    "#                 temp_count += 1\n",
    "#     #             print(temp)\n",
    "#         if not temp_count == 0:\n",
    "#             if data[count][j][66] == 0:\n",
    "#                 slap_L.append(temp / temp_count)\n",
    "#             if data[count][j][66] == 1:\n",
    "#                 slap_R.append(temp / temp_count)\n",
    "#             if data[count][j][66] == 2:\n",
    "#                 pushing_A.append(temp / temp_count)\n",
    "#             if data[count][j][66] == 3:\n",
    "#                 pushing_L.append(temp / temp_count)\n",
    "#             if data[count][j][66] == 4:\n",
    "#                 pushing_R.append(temp / temp_count)\n",
    "#             if data[count][j][66] == 5:\n",
    "#                 punching_L.append(temp / temp_count)\n",
    "#             if data[count][j][66] == 6:\n",
    "#                 puncning_R.append(temp / temp_count)\n",
    "#             if data[count][j][66] == 7:\n",
    "#                 kicking_L.append(temp / temp_count)\n",
    "#             if data[count][j][66] == 8:\n",
    "#                 kicking_R.append(temp / temp_count)\n",
    "#             if data[count][j][66] == 9:\n",
    "#                 tread_L.append(temp / temp_count)\n",
    "#             if data[count][j][66] == 10:\n",
    "#                 tread_R.append(temp / temp_count)\n",
    "#             if data[count][j][66] == 11:\n",
    "#                 footpushing_L.append(temp / temp_count)\n",
    "#             if data[count][j][66] == 12:\n",
    "#                 footpushing_R.append(temp / temp_count)\n",
    "#             if data[count][j][66] == 13 and len(normal) < 40000:\n",
    "#                 normal.append(temp / temp_count)\n",
    "            \n",
    "# plt.plot(slap_L, '--', slap_R, '--', pushing_A, '--', pushing_L, '--', pushing_R, '--', punching_L, '--', puncning_R, '--', kicking_L, '--', kicking_R, '--', tread_L, '--', tread_R, '--', footpushing_L, '--', footpushing_R, '--', normal, 'r--')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "11d9fbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(slap_L, 'r--', slap_R, 'r--', pushing_A, 'r--', pushing_L, 'r--', pushing_R, 'r--', punching_L, 'r--', puncning_R, 'r--', kicking_L, 'g--', kicking_R, 'g--', tread_L, 'g--', tread_R, 'g--', footpushing_L, 'g--', footpushing_R, 'g--', normal, 'b--')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "28e409f0-8d39-435e-8c08-5fad41d4a3ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4115, 2)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5ae18740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8da1ec63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# array([0., 1.],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99a4ccac-2408-4d17-a59d-0a922af6d07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3703, 30, 3) (3703, 2)\n",
      "(412, 30, 3) (412, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8f4f8add-69a4-4877-950b-0641794a0888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 64)                17408     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 19,554\n",
      "Trainable params: 19,554\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2163aeb0-bf60-4862-a205-003df3e6c64d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 1.5065 - acc: 0.6704\n",
      "Epoch 00001: val_acc improved from -inf to 0.91990, saving model to models\\model.h5\n",
      "116/116 [==============================] - 1s 9ms/step - loss: 1.4787 - acc: 0.6759 - val_loss: 0.3848 - val_acc: 0.9199\n",
      "Epoch 2/200\n",
      "112/116 [===========================>..] - ETA: 0s - loss: 0.1319 - acc: 0.9612\n",
      "Epoch 00002: val_acc improved from 0.91990 to 0.93689, saving model to models\\model.h5\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.1306 - acc: 0.9619 - val_loss: 0.5517 - val_acc: 0.9369\n",
      "Epoch 3/200\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 0.0665 - acc: 0.9735\n",
      "Epoch 00003: val_acc improved from 0.93689 to 0.95631, saving model to models\\model.h5\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0645 - acc: 0.9743 - val_loss: 0.1158 - val_acc: 0.9563\n",
      "Epoch 4/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0695 - acc: 0.9787\n",
      "Epoch 00004: val_acc did not improve from 0.95631\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0695 - acc: 0.9787 - val_loss: 0.1335 - val_acc: 0.9539\n",
      "Epoch 5/200\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 0.0464 - acc: 0.9820\n",
      "Epoch 00005: val_acc improved from 0.95631 to 0.97816, saving model to models\\model.h5\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0462 - acc: 0.9822 - val_loss: 0.0927 - val_acc: 0.9782\n",
      "Epoch 6/200\n",
      "110/116 [===========================>..] - ETA: 0s - loss: 0.0412 - acc: 0.9844\n",
      "Epoch 00006: val_acc improved from 0.97816 to 0.98786, saving model to models\\model.h5\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0403 - acc: 0.9849 - val_loss: 0.0562 - val_acc: 0.9879\n",
      "Epoch 7/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 0.0248 - acc: 0.9923\n",
      "Epoch 00007: val_acc did not improve from 0.98786\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0251 - acc: 0.9919 - val_loss: 0.0439 - val_acc: 0.9854\n",
      "Epoch 8/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 0.0176 - acc: 0.9936\n",
      "Epoch 00008: val_acc did not improve from 0.98786\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0173 - acc: 0.9938 - val_loss: 0.0534 - val_acc: 0.9830\n",
      "Epoch 9/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.0103 - acc: 0.9959\n",
      "Epoch 00009: val_acc improved from 0.98786 to 0.99515, saving model to models\\model.h5\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0103 - acc: 0.9959 - val_loss: 0.0243 - val_acc: 0.9951\n",
      "Epoch 10/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 0.0458 - acc: 0.9877\n",
      "Epoch 00010: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0457 - acc: 0.9876 - val_loss: 0.0978 - val_acc: 0.9830\n",
      "Epoch 11/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 0.0263 - acc: 0.9912\n",
      "Epoch 00011: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0260 - acc: 0.9914 - val_loss: 0.0308 - val_acc: 0.9903\n",
      "Epoch 12/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.3085 - acc: 0.9641\n",
      "Epoch 00012: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.3074 - acc: 0.9638 - val_loss: 0.9943 - val_acc: 0.8422\n",
      "Epoch 13/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 3.4914 - acc: 0.6831\n",
      "Epoch 00013: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 3.4548 - acc: 0.6816 - val_loss: 1.9862 - val_acc: 0.6189\n",
      "Epoch 14/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 1.3120 - acc: 0.7571\n",
      "Epoch 00014: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.3636 - acc: 0.7559 - val_loss: 14.0597 - val_acc: 0.4248\n",
      "Epoch 15/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 1.8019 - acc: 0.7160\n",
      "Epoch 00015: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.7926 - acc: 0.7173 - val_loss: 0.4016 - val_acc: 0.7791\n",
      "Epoch 16/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 0.8996 - acc: 0.7448\n",
      "Epoch 00016: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.8923 - acc: 0.7462 - val_loss: 1.4242 - val_acc: 0.6383\n",
      "Epoch 17/200\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 0.2702 - acc: 0.9040\n",
      "Epoch 00017: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.2674 - acc: 0.9047 - val_loss: 0.2174 - val_acc: 0.9150\n",
      "Epoch 18/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 0.1438 - acc: 0.9485\n",
      "Epoch 00018: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.1413 - acc: 0.9503 - val_loss: 0.2132 - val_acc: 0.9175\n",
      "Epoch 19/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 0.1811 - acc: 0.9486\n",
      "Epoch 00019: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.1781 - acc: 0.9495 - val_loss: 0.1388 - val_acc: 0.9563\n",
      "Epoch 20/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9655\n",
      "Epoch 00020: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.1128 - acc: 0.9627 - val_loss: 0.7161 - val_acc: 0.7573\n",
      "Epoch 21/200\n",
      "112/116 [===========================>..] - ETA: 0s - loss: 0.1448 - acc: 0.9509\n",
      "Epoch 00021: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.1408 - acc: 0.9522 - val_loss: 0.1708 - val_acc: 0.9490\n",
      "Epoch 22/200\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 0.0992 - acc: 0.9662\n",
      "Epoch 00022: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0975 - acc: 0.9668 - val_loss: 0.1143 - val_acc: 0.9490\n",
      "Epoch 23/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 0.0704 - acc: 0.9780\n",
      "Epoch 00023: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0687 - acc: 0.9784 - val_loss: 0.0947 - val_acc: 0.9587\n",
      "Epoch 24/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 0.0557 - acc: 0.9827\n",
      "Epoch 00024: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0554 - acc: 0.9830 - val_loss: 0.0899 - val_acc: 0.9612\n",
      "Epoch 25/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0511 - acc: 0.9845\n",
      "Epoch 00025: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0518 - acc: 0.9846 - val_loss: 0.1040 - val_acc: 0.9563\n",
      "Epoch 26/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 0.0541 - acc: 0.9823\n",
      "Epoch 00026: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0516 - acc: 0.9830 - val_loss: 0.0782 - val_acc: 0.9636\n",
      "Epoch 27/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0496 - acc: 0.9838\n",
      "Epoch 00027: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0496 - acc: 0.9838 - val_loss: 0.0960 - val_acc: 0.9612\n",
      "Epoch 28/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9812\n",
      "Epoch 00028: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0543 - acc: 0.9811 - val_loss: 0.0898 - val_acc: 0.9636\n",
      "Epoch 29/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0510 - acc: 0.9839\n",
      "Epoch 00029: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0556 - acc: 0.9838 - val_loss: 0.5367 - val_acc: 0.8495\n",
      "Epoch 30/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.1140 - acc: 0.9606\n",
      "Epoch 00030: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.1140 - acc: 0.9606 - val_loss: 0.1069 - val_acc: 0.9539\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/116 [===========================>..] - ETA: 0s - loss: 0.0937 - acc: 0.9676\n",
      "Epoch 00031: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0927 - acc: 0.9681 - val_loss: 0.2485 - val_acc: 0.9199\n",
      "Epoch 32/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9660\n",
      "Epoch 00032: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0984 - acc: 0.9662 - val_loss: 0.1305 - val_acc: 0.9563\n",
      "Epoch 33/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9718\n",
      "Epoch 00033: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0767 - acc: 0.9722 - val_loss: 0.0851 - val_acc: 0.9684\n",
      "Epoch 34/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0725 - acc: 0.9730\n",
      "Epoch 00034: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0725 - acc: 0.9730 - val_loss: 0.1541 - val_acc: 0.9515\n",
      "Epoch 35/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0929 - acc: 0.9727\n",
      "Epoch 00035: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0929 - acc: 0.9727 - val_loss: 0.0818 - val_acc: 0.9709\n",
      "Epoch 36/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0605 - acc: 0.9800\n",
      "Epoch 00036: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0605 - acc: 0.9800 - val_loss: 0.0581 - val_acc: 0.9782\n",
      "Epoch 37/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0654 - acc: 0.9860\n",
      "Epoch 00037: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0638 - acc: 0.9857 - val_loss: 0.0459 - val_acc: 0.9854\n",
      "Epoch 38/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.0771 - acc: 0.9758\n",
      "Epoch 00038: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0778 - acc: 0.9754 - val_loss: 0.1820 - val_acc: 0.9320\n",
      "Epoch 39/200\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 1.1002 - acc: 0.8899\n",
      "Epoch 00039: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 1.0626 - acc: 0.8920 - val_loss: 0.1805 - val_acc: 0.9466\n",
      "Epoch 40/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.0748 - acc: 0.9785\n",
      "Epoch 00040: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0744 - acc: 0.9787 - val_loss: 0.1398 - val_acc: 0.9466\n",
      "Epoch 41/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.0537 - acc: 0.9807\n",
      "Epoch 00041: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0535 - acc: 0.9808 - val_loss: 0.1324 - val_acc: 0.9490\n",
      "Epoch 42/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0567 - acc: 0.9814\n",
      "Epoch 00042: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0550 - acc: 0.9816 - val_loss: 0.1141 - val_acc: 0.9587\n",
      "Epoch 43/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0495 - acc: 0.9814\n",
      "Epoch 00043: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0495 - acc: 0.9814 - val_loss: 0.1100 - val_acc: 0.9563\n",
      "Epoch 44/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0428 - acc: 0.9839\n",
      "Epoch 00044: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0458 - acc: 0.9822 - val_loss: 0.1808 - val_acc: 0.9466\n",
      "Epoch 45/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0449 - acc: 0.9837\n",
      "Epoch 00045: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0454 - acc: 0.9838 - val_loss: 0.0938 - val_acc: 0.9636\n",
      "Epoch 46/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 0.0400 - acc: 0.9846\n",
      "Epoch 00046: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0413 - acc: 0.9843 - val_loss: 0.2019 - val_acc: 0.9417\n",
      "Epoch 47/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0401 - acc: 0.9846\n",
      "Epoch 00047: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0401 - acc: 0.9846 - val_loss: 0.0829 - val_acc: 0.9684\n",
      "Epoch 48/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 0.0358 - acc: 0.9864\n",
      "Epoch 00048: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0353 - acc: 0.9865 - val_loss: 0.0582 - val_acc: 0.9757\n",
      "Epoch 49/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 0.0311 - acc: 0.9879\n",
      "Epoch 00049: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0307 - acc: 0.9881 - val_loss: 0.0463 - val_acc: 0.9757\n",
      "Epoch 50/200\n",
      "110/116 [===========================>..] - ETA: 0s - loss: 0.0223 - acc: 0.9932\n",
      "Epoch 00050: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0222 - acc: 0.9932 - val_loss: 0.0394 - val_acc: 0.9782\n",
      "Epoch 51/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0186 - acc: 0.9935\n",
      "Epoch 00051: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0186 - acc: 0.9935 - val_loss: 0.0419 - val_acc: 0.9806\n",
      "Epoch 52/200\n",
      "110/116 [===========================>..] - ETA: 0s - loss: 0.0337 - acc: 0.9884\n",
      "Epoch 00052: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 8ms/step - loss: 0.0335 - acc: 0.9878 - val_loss: 0.0478 - val_acc: 0.9806\n",
      "Epoch 53/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 0.0150 - acc: 0.9951\n",
      "Epoch 00053: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 9ms/step - loss: 0.0148 - acc: 0.9951 - val_loss: 0.0261 - val_acc: 0.9903\n",
      "Epoch 54/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0128 - acc: 0.9960\n",
      "Epoch 00054: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0124 - acc: 0.9962 - val_loss: 0.0384 - val_acc: 0.9879\n",
      "Epoch 55/200\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 0.0141 - acc: 0.9947\n",
      "Epoch 00055: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 8ms/step - loss: 0.0141 - acc: 0.9946 - val_loss: 0.0308 - val_acc: 0.9879\n",
      "Epoch 56/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 0.0119 - acc: 0.9961\n",
      "Epoch 00056: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0120 - acc: 0.9959 - val_loss: 0.0240 - val_acc: 0.9903\n",
      "Epoch 57/200\n",
      "112/116 [===========================>..] - ETA: 0s - loss: 0.0080 - acc: 0.9975\n",
      "Epoch 00057: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0078 - acc: 0.9976 - val_loss: 0.0222 - val_acc: 0.9903\n",
      "Epoch 58/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 0.0109 - acc: 0.9962\n",
      "Epoch 00058: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 8ms/step - loss: 0.0107 - acc: 0.9962 - val_loss: 0.0262 - val_acc: 0.9927\n",
      "Epoch 59/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 0.0071 - acc: 0.9977\n",
      "Epoch 00059: val_acc did not improve from 0.99515\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0068 - acc: 0.9978 - val_loss: 0.0345 - val_acc: 0.9903\n",
      "Epoch 60/200\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 0.0086 - acc: 0.9963\n",
      "Epoch 00060: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0083 - acc: 0.9965 - val_loss: 0.0144 - val_acc: 0.9927\n",
      "Epoch 61/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 0.0058 - acc: 0.9983\n",
      "Epoch 00061: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0057 - acc: 0.9984 - val_loss: 0.0227 - val_acc: 0.9927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "110/116 [===========================>..] - ETA: 0s - loss: 0.0048 - acc: 0.9986\n",
      "Epoch 00062: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0053 - acc: 0.9984 - val_loss: 0.0154 - val_acc: 0.9903\n",
      "Epoch 63/200\n",
      "110/116 [===========================>..] - ETA: 0s - loss: 0.0043 - acc: 0.9983\n",
      "Epoch 00063: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0053 - acc: 0.9981 - val_loss: 0.0148 - val_acc: 0.9951\n",
      "Epoch 64/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0045 - acc: 0.9989\n",
      "Epoch 00064: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0045 - acc: 0.9989 - val_loss: 0.0129 - val_acc: 0.9951\n",
      "Epoch 65/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0047 - acc: 0.9983\n",
      "Epoch 00065: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0045 - acc: 0.9984 - val_loss: 0.0095 - val_acc: 0.9951\n",
      "Epoch 66/200\n",
      "112/116 [===========================>..] - ETA: 0s - loss: 0.0032 - acc: 0.9989\n",
      "Epoch 00066: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0031 - acc: 0.9989 - val_loss: 0.0175 - val_acc: 0.9927\n",
      "Epoch 67/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0037 - acc: 0.9991\n",
      "Epoch 00067: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0036 - acc: 0.9992 - val_loss: 0.0102 - val_acc: 0.9951\n",
      "Epoch 68/200\n",
      "110/116 [===========================>..] - ETA: 0s - loss: 0.0029 - acc: 0.9994\n",
      "Epoch 00068: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0028 - acc: 0.9995 - val_loss: 0.0115 - val_acc: 0.9951\n",
      "Epoch 69/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0040 - acc: 0.9986\n",
      "Epoch 00069: val_acc did not improve from 0.99515\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0040 - acc: 0.9986 - val_loss: 0.0086 - val_acc: 0.9951\n",
      "Epoch 70/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 0.0022 - acc: 0.9994\n",
      "Epoch 00070: val_acc improved from 0.99515 to 1.00000, saving model to models\\model.h5\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0021 - acc: 0.9995 - val_loss: 0.0035 - val_acc: 1.0000\n",
      "Epoch 71/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 0.0026 - acc: 0.9991\n",
      "Epoch 00071: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0025 - acc: 0.9992 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 0.0012 - acc: 0.9997   \n",
      "Epoch 00072: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 0.0033 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0014 - acc: 0.9997\n",
      "Epoch 00073: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0014 - acc: 0.9997 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 00074: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 8.4885e-04 - acc: 1.0000\n",
      "Epoch 00075: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 8.1022e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "112/116 [===========================>..] - ETA: 0s - loss: 7.6161e-04 - acc: 1.0000\n",
      "Epoch 00076: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 7.7508e-04 - acc: 1.0000 - val_loss: 0.0019 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 7.2219e-04 - acc: 1.0000\n",
      "Epoch 00077: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 7.2219e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.1643e-04 - acc: 1.0000\n",
      "Epoch 00078: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 8.1643e-04 - acc: 1.0000 - val_loss: 0.0021 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 5.6513e-04 - acc: 1.0000\n",
      "Epoch 00079: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 5.5155e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 80/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 5.1675e-04 - acc: 1.0000\n",
      "Epoch 00080: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 5.1733e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.5715e-04 - acc: 1.0000\n",
      "Epoch 00081: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 5.5715e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 4.3851e-04 - acc: 1.0000\n",
      "Epoch 00082: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 4.3599e-04 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.1463e-04 - acc: 1.0000\n",
      "Epoch 00083: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 5.1463e-04 - acc: 1.0000 - val_loss: 0.0022 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 3.1897e-04 - acc: 1.0000\n",
      "Epoch 00084: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 3.4441e-04 - acc: 1.0000 - val_loss: 0.0011 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.7799e-04 - acc: 1.0000\n",
      "Epoch 00085: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 5.7799e-04 - acc: 1.0000 - val_loss: 0.0027 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 2.9280e-04 - acc: 1.0000\n",
      "Epoch 00086: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.9127e-04 - acc: 1.0000 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 4.3335e-04 - acc: 1.0000\n",
      "Epoch 00087: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 4.3504e-04 - acc: 1.0000 - val_loss: 0.0059 - val_acc: 0.9951\n",
      "Epoch 88/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 3.6174e-04 - acc: 1.0000\n",
      "Epoch 00088: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 3.4192e-04 - acc: 1.0000 - val_loss: 0.0018 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 2.4114e-04 - acc: 1.0000\n",
      "Epoch 00089: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.3982e-04 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "110/116 [===========================>..] - ETA: 0s - loss: 2.1041e-04 - acc: 1.0000\n",
      "Epoch 00090: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.0378e-04 - acc: 1.0000 - val_loss: 0.0015 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 2.1206e-04 - acc: 1.0000\n",
      "Epoch 00091: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.1185e-04 - acc: 1.0000 - val_loss: 0.0078 - val_acc: 0.9976\n",
      "Epoch 92/200\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 2.3358e-04 - acc: 1.0000\n",
      "Epoch 00092: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.2855e-04 - acc: 1.0000 - val_loss: 0.0014 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3622e-04 - acc: 1.0000\n",
      "Epoch 00093: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.3622e-04 - acc: 1.0000 - val_loss: 0.0049 - val_acc: 0.9976\n",
      "Epoch 94/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 1.3369e-04 - acc: 1.0000\n",
      "Epoch 00094: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.2923e-04 - acc: 1.0000 - val_loss: 0.0023 - val_acc: 0.9976\n",
      "Epoch 95/200\n",
      "110/116 [===========================>..] - ETA: 0s - loss: 1.2874e-04 - acc: 1.0000\n",
      "Epoch 00095: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 1.2309e-04 - acc: 1.0000 - val_loss: 0.0031 - val_acc: 0.9976\n",
      "Epoch 96/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 1.1628e-04 - acc: 1.0000\n",
      "Epoch 00096: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 1.1559e-04 - acc: 1.0000 - val_loss: 0.0047 - val_acc: 0.9976\n",
      "Epoch 97/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 1.1735e-04 - acc: 1.0000\n",
      "Epoch 00097: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.1594e-04 - acc: 1.0000 - val_loss: 0.0082 - val_acc: 0.9976\n",
      "Epoch 98/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 1.1003e-04 - acc: 1.0000\n",
      "Epoch 00098: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.0949e-04 - acc: 1.0000 - val_loss: 0.0066 - val_acc: 0.9976\n",
      "Epoch 99/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 9.3250e-05 - acc: 1.0000\n",
      "Epoch 00099: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 9.2111e-05 - acc: 1.0000 - val_loss: 0.0088 - val_acc: 0.9976\n",
      "Epoch 100/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 9.7147e-05 - acc: 1.0000\n",
      "Epoch 00100: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 9.2908e-05 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 9.1461e-05 - acc: 1.0000\n",
      "Epoch 00101: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 8.8167e-05 - acc: 1.0000 - val_loss: 0.0081 - val_acc: 0.9976\n",
      "Epoch 102/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 1.0115e-04 - acc: 1.0000\n",
      "Epoch 00102: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 9.6362e-05 - acc: 1.0000 - val_loss: 0.0045 - val_acc: 0.9976\n",
      "Epoch 103/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 8.6671e-05 - acc: 1.0000\n",
      "Epoch 00103: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 8.2853e-05 - acc: 1.0000 - val_loss: 0.0061 - val_acc: 0.9976\n",
      "Epoch 104/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 8.6155e-05 - acc: 1.0000\n",
      "Epoch 00104: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 8.1878e-05 - acc: 1.0000 - val_loss: 0.0032 - val_acc: 0.9976\n",
      "Epoch 105/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 7.1544e-05 - acc: 1.0000\n",
      "Epoch 00105: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 6.9926e-05 - acc: 1.0000 - val_loss: 0.0176 - val_acc: 0.9976\n",
      "Epoch 106/200\n",
      "110/116 [===========================>..] - ETA: 0s - loss: 6.0466e-05 - acc: 1.0000\n",
      "Epoch 00106: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 5.9780e-05 - acc: 1.0000 - val_loss: 0.0085 - val_acc: 0.9976\n",
      "Epoch 107/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 4.8277e-05 - acc: 1.0000\n",
      "Epoch 00107: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 4.8076e-05 - acc: 1.0000 - val_loss: 0.0051 - val_acc: 0.9976\n",
      "Epoch 108/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 5.0014e-05 - acc: 1.0000\n",
      "Epoch 00108: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 5.0337e-05 - acc: 1.0000 - val_loss: 0.0086 - val_acc: 0.9976\n",
      "Epoch 109/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 5.4763e-05 - acc: 1.0000\n",
      "Epoch 00109: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 5.4763e-05 - acc: 1.0000 - val_loss: 0.0145 - val_acc: 0.9976\n",
      "Epoch 110/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 3.7332e-05 - acc: 1.0000\n",
      "Epoch 00110: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 4.1622e-05 - acc: 1.0000 - val_loss: 0.0132 - val_acc: 0.9976\n",
      "Epoch 111/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 4.2459e-05 - acc: 1.0000\n",
      "Epoch 00111: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 4.1321e-05 - acc: 1.0000 - val_loss: 0.0119 - val_acc: 0.9976\n",
      "Epoch 112/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 3.7277e-05 - acc: 1.0000\n",
      "Epoch 00112: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 3.7112e-05 - acc: 1.0000 - val_loss: 0.0128 - val_acc: 0.9976\n",
      "Epoch 113/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 2.8028e-05 - acc: 1.0000\n",
      "Epoch 00113: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 3.0919e-05 - acc: 1.0000 - val_loss: 0.0157 - val_acc: 0.9976\n",
      "Epoch 114/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 3.6657e-05 - acc: 1.0000\n",
      "Epoch 00114: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 3.6657e-05 - acc: 1.0000 - val_loss: 0.0266 - val_acc: 0.9976\n",
      "Epoch 115/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 2.8267e-05 - acc: 1.0000\n",
      "Epoch 00115: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.6994e-05 - acc: 1.0000 - val_loss: 0.0173 - val_acc: 0.9976\n",
      "Epoch 116/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 2.5483e-05 - acc: 1.0000\n",
      "Epoch 00116: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.6844e-05 - acc: 1.0000 - val_loss: 0.0462 - val_acc: 0.9976\n",
      "Epoch 117/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 2.4410e-05 - acc: 1.0000\n",
      "Epoch 00117: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.4410e-05 - acc: 1.0000 - val_loss: 0.0582 - val_acc: 0.9976\n",
      "Epoch 118/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 2.2566e-05 - acc: 1.0000\n",
      "Epoch 00118: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.3052e-05 - acc: 1.0000 - val_loss: 0.0605 - val_acc: 0.9976\n",
      "Epoch 119/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 2.5883e-05 - acc: 1.0000\n",
      "Epoch 00119: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.5546e-05 - acc: 1.0000 - val_loss: 0.0526 - val_acc: 0.9976\n",
      "Epoch 120/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 2.0989e-05 - acc: 1.0000\n",
      "Epoch 00120: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 00120: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.2966e-05 - acc: 1.0000 - val_loss: 0.0609 - val_acc: 0.9976\n",
      "Epoch 121/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 1.8617e-05 - acc: 1.0000\n",
      "Epoch 00121: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.7776e-05 - acc: 1.0000 - val_loss: 0.0646 - val_acc: 0.9976\n",
      "Epoch 122/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7088e-05 - acc: 1.0000\n",
      "Epoch 00122: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.7088e-05 - acc: 1.0000 - val_loss: 0.0618 - val_acc: 0.9976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 1.7087e-05 - acc: 1.0000\n",
      "Epoch 00123: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.6426e-05 - acc: 1.0000 - val_loss: 0.0641 - val_acc: 0.9976\n",
      "Epoch 124/200\n",
      "112/116 [===========================>..] - ETA: 0s - loss: 1.5516e-05 - acc: 1.0000\n",
      "Epoch 00124: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 1.5152e-05 - acc: 1.0000 - val_loss: 0.0617 - val_acc: 0.9976\n",
      "Epoch 125/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4941e-05 - acc: 1.0000\n",
      "Epoch 00125: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.4941e-05 - acc: 1.0000 - val_loss: 0.0633 - val_acc: 0.9976\n",
      "Epoch 126/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3761e-05 - acc: 1.0000\n",
      "Epoch 00126: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.3761e-05 - acc: 1.0000 - val_loss: 0.0644 - val_acc: 0.9976\n",
      "Epoch 127/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 1.4173e-05 - acc: 1.0000\n",
      "Epoch 00127: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.4088e-05 - acc: 1.0000 - val_loss: 0.0643 - val_acc: 0.9976\n",
      "Epoch 128/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 1.3477e-05 - acc: 1.0000\n",
      "Epoch 00128: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.2935e-05 - acc: 1.0000 - val_loss: 0.0639 - val_acc: 0.9976\n",
      "Epoch 129/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 1.3232e-05 - acc: 1.0000\n",
      "Epoch 00129: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.3417e-05 - acc: 1.0000 - val_loss: 0.0732 - val_acc: 0.9976\n",
      "Epoch 130/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 1.1797e-05 - acc: 1.0000\n",
      "Epoch 00130: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.1977e-05 - acc: 1.0000 - val_loss: 0.0663 - val_acc: 0.9976\n",
      "Epoch 131/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 9.8521e-06 - acc: 1.0000\n",
      "Epoch 00131: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.1858e-05 - acc: 1.0000 - val_loss: 0.0703 - val_acc: 0.9976\n",
      "Epoch 132/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 1.2361e-05 - acc: 1.0000\n",
      "Epoch 00132: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 1.2288e-05 - acc: 1.0000 - val_loss: 0.0709 - val_acc: 0.9976\n",
      "Epoch 133/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 1.1024e-05 - acc: 1.0000\n",
      "Epoch 00133: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.1185e-05 - acc: 1.0000 - val_loss: 0.0710 - val_acc: 0.9976\n",
      "Epoch 134/200\n",
      "112/116 [===========================>..] - ETA: 0s - loss: 1.0019e-05 - acc: 1.0000\n",
      "Epoch 00134: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 9.7348e-06 - acc: 1.0000 - val_loss: 0.0678 - val_acc: 0.9976\n",
      "Epoch 135/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 8.8638e-06 - acc: 1.0000\n",
      "Epoch 00135: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 8.8977e-06 - acc: 1.0000 - val_loss: 0.0747 - val_acc: 0.9976\n",
      "Epoch 136/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.6244e-06 - acc: 1.0000\n",
      "Epoch 00136: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 8.6244e-06 - acc: 1.0000 - val_loss: 0.0702 - val_acc: 0.9976\n",
      "Epoch 137/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 8.7363e-06 - acc: 1.0000\n",
      "Epoch 00137: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 8.5269e-06 - acc: 1.0000 - val_loss: 0.0709 - val_acc: 0.9976\n",
      "Epoch 138/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 7.9904e-06 - acc: 1.0000\n",
      "Epoch 00138: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 8.0739e-06 - acc: 1.0000 - val_loss: 0.0747 - val_acc: 0.9976\n",
      "Epoch 139/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 7.3960e-06 - acc: 1.0000\n",
      "Epoch 00139: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 7.2814e-06 - acc: 1.0000 - val_loss: 0.0699 - val_acc: 0.9976\n",
      "Epoch 140/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 7.9234e-06 - acc: 1.0000\n",
      "Epoch 00140: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 7.6572e-06 - acc: 1.0000 - val_loss: 0.0792 - val_acc: 0.9976\n",
      "Epoch 141/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 6.4965e-06 - acc: 1.0000\n",
      "Epoch 00141: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 6.7123e-06 - acc: 1.0000 - val_loss: 0.0789 - val_acc: 0.9976\n",
      "Epoch 142/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 5.5104e-06 - acc: 1.0000\n",
      "Epoch 00142: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 6.2335e-06 - acc: 1.0000 - val_loss: 0.0747 - val_acc: 0.9976\n",
      "Epoch 143/200\n",
      "112/116 [===========================>..] - ETA: 0s - loss: 6.4245e-06 - acc: 1.0000\n",
      "Epoch 00143: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 6.4978e-06 - acc: 1.0000 - val_loss: 0.0775 - val_acc: 0.9976\n",
      "Epoch 144/200\n",
      "110/116 [===========================>..] - ETA: 0s - loss: 5.6390e-06 - acc: 1.0000\n",
      "Epoch 00144: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 5.5532e-06 - acc: 1.0000 - val_loss: 0.0790 - val_acc: 0.9976\n",
      "Epoch 145/200\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 5.5706e-06 - acc: 1.0000\n",
      "Epoch 00145: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 5.5508e-06 - acc: 1.0000 - val_loss: 0.0771 - val_acc: 0.9976\n",
      "Epoch 146/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 5.6465e-06 - acc: 1.0000\n",
      "Epoch 00146: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 5.6102e-06 - acc: 1.0000 - val_loss: 0.0801 - val_acc: 0.9976\n",
      "Epoch 147/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 4.7284e-06 - acc: 1.0000\n",
      "Epoch 00147: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 4.7015e-06 - acc: 1.0000 - val_loss: 0.0795 - val_acc: 0.9976\n",
      "Epoch 148/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 4.7390e-06 - acc: 1.0000\n",
      "Epoch 00148: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 4.5995e-06 - acc: 1.0000 - val_loss: 0.0898 - val_acc: 0.9976\n",
      "Epoch 149/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 4.4281e-06 - acc: 1.0000\n",
      "Epoch 00149: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 4.4981e-06 - acc: 1.0000 - val_loss: 0.1711 - val_acc: 0.9951\n",
      "Epoch 150/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 3.5668e-06 - acc: 1.0000\n",
      "Epoch 00150: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 3.7119e-06 - acc: 1.0000 - val_loss: 0.1640 - val_acc: 0.9951\n",
      "Epoch 151/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 3.8150e-06 - acc: 1.0000\n",
      "Epoch 00151: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 3.8452e-06 - acc: 1.0000 - val_loss: 0.1406 - val_acc: 0.9951\n",
      "Epoch 152/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 3.5671e-06 - acc: 1.0000\n",
      "Epoch 00152: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 3.4462e-06 - acc: 1.0000 - val_loss: 0.1015 - val_acc: 0.9951\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114/116 [============================>.] - ETA: 0s - loss: 3.4426e-06 - acc: 1.0000\n",
      "Epoch 00153: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 3.4261e-06 - acc: 1.0000 - val_loss: 0.1103 - val_acc: 0.9951\n",
      "Epoch 154/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 3.2143e-06 - acc: 1.0000\n",
      "Epoch 00154: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 3.2209e-06 - acc: 1.0000 - val_loss: 0.1552 - val_acc: 0.9927\n",
      "Epoch 155/200\n",
      "112/116 [===========================>..] - ETA: 0s - loss: 2.9739e-06 - acc: 1.0000\n",
      "Epoch 00155: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.9343e-06 - acc: 1.0000 - val_loss: 0.1903 - val_acc: 0.9927\n",
      "Epoch 156/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 2.6160e-06 - acc: 1.0000\n",
      "Epoch 00156: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.6572e-06 - acc: 1.0000 - val_loss: 0.1916 - val_acc: 0.9903\n",
      "Epoch 157/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 2.6944e-06 - acc: 1.0000\n",
      "Epoch 00157: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.6571e-06 - acc: 1.0000 - val_loss: 0.3189 - val_acc: 0.9927\n",
      "Epoch 158/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 2.5044e-06 - acc: 1.0000\n",
      "Epoch 00158: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.4561e-06 - acc: 1.0000 - val_loss: 0.1540 - val_acc: 0.9951\n",
      "Epoch 159/200\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 2.2010e-06 - acc: 1.0000\n",
      "Epoch 00159: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 2.3545e-06 - acc: 1.0000 - val_loss: 0.1036 - val_acc: 0.9976\n",
      "Epoch 160/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 2.1080e-06 - acc: 1.0000\n",
      "Epoch 00160: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 2.1755e-06 - acc: 1.0000 - val_loss: 0.1053 - val_acc: 0.9976\n",
      "Epoch 161/200\n",
      "112/116 [===========================>..] - ETA: 0s - loss: 1.7720e-06 - acc: 1.0000\n",
      "Epoch 00161: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 1.8942e-06 - acc: 1.0000 - val_loss: 0.1041 - val_acc: 0.9976\n",
      "Epoch 162/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.7828e-06 - acc: 1.0000\n",
      "Epoch 00162: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.7828e-06 - acc: 1.0000 - val_loss: 0.1066 - val_acc: 0.9976\n",
      "Epoch 163/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 1.6439e-06 - acc: 1.0000\n",
      "Epoch 00163: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 1.6479e-06 - acc: 1.0000 - val_loss: 0.1061 - val_acc: 0.9976\n",
      "Epoch 164/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 1.6731e-06 - acc: 1.0000\n",
      "Epoch 00164: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 1.5933e-06 - acc: 1.0000 - val_loss: 0.1071 - val_acc: 0.9976\n",
      "Epoch 165/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.4347e-06 - acc: 1.0000\n",
      "Epoch 00165: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 1.4347e-06 - acc: 1.0000 - val_loss: 0.1106 - val_acc: 0.9976\n",
      "Epoch 166/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 1.3709e-06 - acc: 1.0000\n",
      "Epoch 00166: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 1.3709e-06 - acc: 1.0000 - val_loss: 0.1093 - val_acc: 0.9976\n",
      "Epoch 167/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 1.2430e-06 - acc: 1.0000\n",
      "Epoch 00167: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.2225e-06 - acc: 1.0000 - val_loss: 0.1125 - val_acc: 0.9976\n",
      "Epoch 168/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 1.2554e-06 - acc: 1.0000\n",
      "Epoch 00168: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.2141e-06 - acc: 1.0000 - val_loss: 0.1160 - val_acc: 0.9976\n",
      "Epoch 169/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 1.0665e-06 - acc: 1.0000\n",
      "Epoch 00169: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 1.0604e-06 - acc: 1.0000 - val_loss: 0.1111 - val_acc: 0.9976\n",
      "Epoch 170/200\n",
      "112/116 [===========================>..] - ETA: 0s - loss: 1.0221e-06 - acc: 1.0000\n",
      "Epoch 00170: val_acc did not improve from 1.00000\n",
      "\n",
      "Epoch 00170: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 1.0785e-06 - acc: 1.0000 - val_loss: 0.1186 - val_acc: 0.9976\n",
      "Epoch 171/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 1.0086e-06 - acc: 1.0000\n",
      "Epoch 00171: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 9.8558e-07 - acc: 1.0000 - val_loss: 0.1191 - val_acc: 0.9976\n",
      "Epoch 172/200\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 9.4123e-07 - acc: 1.0000\n",
      "Epoch 00172: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 9.2062e-07 - acc: 1.0000 - val_loss: 0.1188 - val_acc: 0.9976\n",
      "Epoch 173/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 9.4911e-07 - acc: 1.0000\n",
      "Epoch 00173: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 8.9166e-07 - acc: 1.0000 - val_loss: 0.1206 - val_acc: 0.9976\n",
      "Epoch 174/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 8.9547e-07 - acc: 1.0000\n",
      "Epoch 00174: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 8.9735e-07 - acc: 1.0000 - val_loss: 0.1213 - val_acc: 0.9976\n",
      "Epoch 175/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 8.2744e-07 - acc: 1.0000\n",
      "Epoch 00175: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 8.2744e-07 - acc: 1.0000 - val_loss: 0.1213 - val_acc: 0.9976\n",
      "Epoch 176/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 0.1184 - acc: 0.9757 \n",
      "Epoch 00176: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.1163 - acc: 0.9746 - val_loss: 0.1984 - val_acc: 0.9490\n",
      "Epoch 177/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0293 - acc: 0.9885\n",
      "Epoch 00177: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0284 - acc: 0.9889 - val_loss: 0.0453 - val_acc: 0.9806\n",
      "Epoch 178/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0139 - acc: 0.9934\n",
      "Epoch 00178: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0142 - acc: 0.9932 - val_loss: 0.0242 - val_acc: 0.9879\n",
      "Epoch 179/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0110 - acc: 0.9957\n",
      "Epoch 00179: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0110 - acc: 0.9957 - val_loss: 0.0173 - val_acc: 0.9951\n",
      "Epoch 180/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0072 - acc: 0.9974\n",
      "Epoch 00180: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0069 - acc: 0.9976 - val_loss: 0.0117 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 0.0054 - acc: 0.9986\n",
      "Epoch 00181: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0053 - acc: 0.9986 - val_loss: 0.0099 - val_acc: 1.0000\n",
      "Epoch 182/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0046 - acc: 0.9992\n",
      "Epoch 00182: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0046 - acc: 0.9992 - val_loss: 0.0070 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 183/200\n",
      "110/116 [===========================>..] - ETA: 0s - loss: 0.0035 - acc: 0.9991\n",
      "Epoch 00183: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0034 - acc: 0.9992 - val_loss: 0.0051 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "110/116 [===========================>..] - ETA: 0s - loss: 0.0028 - acc: 0.9994\n",
      "Epoch 00184: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0027 - acc: 0.9995 - val_loss: 0.0041 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "113/116 [============================>.] - ETA: 0s - loss: 0.0024 - acc: 0.9997\n",
      "Epoch 00185: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0024 - acc: 0.9997 - val_loss: 0.0043 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0035 - acc: 0.9994\n",
      "Epoch 00186: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0038 - acc: 0.9992 - val_loss: 0.0046 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "116/116 [==============================] - ETA: 0s - loss: 0.0034 - acc: 0.9997\n",
      "Epoch 00187: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0034 - acc: 0.9997 - val_loss: 0.0052 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.0030 - acc: 0.9995\n",
      "Epoch 00188: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0030 - acc: 0.9995 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 0.0025 - acc: 0.9997\n",
      "Epoch 00189: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0024 - acc: 0.9997 - val_loss: 0.0028 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 0.0023 - acc: 0.9995\n",
      "Epoch 00190: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0023 - acc: 0.9995 - val_loss: 0.0032 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "110/116 [===========================>..] - ETA: 0s - loss: 0.0020 - acc: 0.9997\n",
      "Epoch 00191: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0019 - acc: 0.9997 - val_loss: 0.0020 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.0017 - acc: 0.9997\n",
      "Epoch 00192: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0017 - acc: 0.9997 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "108/116 [==========================>...] - ETA: 0s - loss: 0.0015 - acc: 0.9997\n",
      "Epoch 00193: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0015 - acc: 0.9997 - val_loss: 0.0016 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 0.0013 - acc: 1.0000\n",
      "Epoch 00194: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.0013 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 00195: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.0012 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 0.0010 - acc: 1.0000   \n",
      "Epoch 00196: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.0017 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "109/116 [===========================>..] - ETA: 0s - loss: 9.1792e-04 - acc: 1.0000\n",
      "Epoch 00197: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 9.0118e-04 - acc: 1.0000 - val_loss: 8.3121e-04 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "115/116 [============================>.] - ETA: 0s - loss: 6.8418e-04 - acc: 1.0000\n",
      "Epoch 00198: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 6.8174e-04 - acc: 1.0000 - val_loss: 6.4412e-04 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "111/116 [===========================>..] - ETA: 0s - loss: 0.0029 - acc: 0.9994\n",
      "Epoch 00199: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 7ms/step - loss: 0.0028 - acc: 0.9995 - val_loss: 9.5166e-04 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "114/116 [============================>.] - ETA: 0s - loss: 5.1197e-04 - acc: 1.0000\n",
      "Epoch 00200: val_acc did not improve from 1.00000\n",
      "116/116 [==============================] - 1s 6ms/step - loss: 5.0553e-04 - acc: 1.0000 - val_loss: 4.3696e-04 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fd950b19-8ab5-48f3-a818-b7e155f66b4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots(figsize=(16, 10))\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1fb8422-096c-4221-bcee-81c053174c53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[144,   0],\n",
       "        [  0, 268]],\n",
       "\n",
       "       [[268,   0],\n",
       "        [  0, 144]]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('models/model.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc726d6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
