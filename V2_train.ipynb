{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df266d2b-0f34-4579-80a8-398a68e652b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b02a96a-bb28-4939-8b57-cec35a1c6ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow-gpu==2.3.0\n",
    "# !pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed352fe7-1d49-4531-b5df-1d7b4fae3386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d79d76f7-1209-4ee7-8230-e09d5f1b162f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66042040-399a-4838-a00e-8e8bda8db4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-5-17bb7203622b>:1: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a36f5f7b-fce3-47f6-a5e0-bf553ab72e66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 16503307398752191630,\n",
       " name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 8052953285104884725\n",
       " physical_device_desc: \"device: XLA_CPU device\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd72a9c2-68ef-469d-ab07-cf21f7b2f842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50251, 30, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# part = 'right_arm'\n",
    "# part = 'left_arm'\n",
    "# part = 'right_leg' \n",
    "part = 'left_leg'\n",
    "\n",
    "actions = ['assult', 'normal']\n",
    "\n",
    "file_dir = 'C:/Users/BVer/are_you_ok/dataset/' + part + '/'#part 폴더를 dataset 폴더에 넣어주세요\n",
    "\n",
    "npy_file = []\n",
    "for name in os.listdir(file_dir):\n",
    "    if not len(np.load(file_dir + name)) == 0:\n",
    "        npy_file.append(np.load(file_dir + name))\n",
    "\n",
    "data = np.concatenate(npy_file, axis=0)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08b8a12a-2dd5-4fb7-b5bc-1c05a7a3f0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "if part == 'right_arm':\n",
    "    for i in range(len(data)):\n",
    "        for j in range(30):\n",
    "            if data[i][j][2] in [1, 2, 4, 6]:\n",
    "                data[i][j][2] = 0\n",
    "            else: data[i][j][2] = 1\n",
    "elif part == 'left_arm':\n",
    "    for i in range(len(data)):\n",
    "        for j in range(30):\n",
    "            if data[i][j][2] in [0, 2, 3, 5]:\n",
    "                data[i][j][2] = 0\n",
    "            else: data[i][j][2] = 1\n",
    "elif part == 'right_leg':\n",
    "    for i in range(len(data)):\n",
    "        for j in range(30):\n",
    "            if data[i][j][2] in [8, 10, 12]:\n",
    "                data[i][j][2] = 0\n",
    "            else: data[i][j][2] = 1\n",
    "elif part == 'left_leg':\n",
    "    for i in range(len(data)):\n",
    "        for j in range(30):\n",
    "            if data[i][j][2] in [7, 9, 11]:\n",
    "                data[i][j][2] = 0\n",
    "            else: data[i][j][2] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ffbc0b4-6ba3-49ca-90a1-3a9afa3125a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50251, 30, 2)\n",
      "(50251,)\n"
     ]
    }
   ],
   "source": [
    "x_data = data[:, :, :-1]\n",
    "labels = data[:, 0, -1]\n",
    "\n",
    "print(x_data.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28e409f0-8d39-435e-8c08-5fad41d4a3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50251, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_data = to_categorical(labels, num_classes=len(actions))\n",
    "y_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69b370c1-9333-4b05-8c82-2665b3ce9003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99a4ccac-2408-4d17-a59d-0a922af6d07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45225, 30, 2) (45225, 2)\n",
      "(5026, 30, 2) (5026, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_data = x_data.astype(np.float32)\n",
    "y_data = y_data.astype(np.float32)\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.1, random_state=2021)\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f4f8add-69a4-4877-950b-0641794a0888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 64)                17152     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 19,298\n",
      "Trainable params: 19,298\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, activation='relu', input_shape=x_train.shape[1:3]),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(actions), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2163aeb0-bf60-4862-a205-003df3e6c64d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 1.3420 - acc: 0.9683\n",
      "Epoch 00001: val_acc improved from -inf to 0.96439, saving model to models\\left_leg_model.h5\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 1.3416 - acc: 0.9683 - val_loss: 0.3088 - val_acc: 0.9644\n",
      "Epoch 2/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 38.6526 - acc: 0.9683\n",
      "Epoch 00002: val_acc improved from 0.96439 to 0.97214, saving model to models\\left_leg_model.h5\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 38.4548 - acc: 0.9683 - val_loss: 0.2430 - val_acc: 0.9721\n",
      "Epoch 3/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 1.9866 - acc: 0.9724\n",
      "Epoch 00003: val_acc improved from 0.97214 to 0.97791, saving model to models\\left_leg_model.h5\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 1.9834 - acc: 0.9724 - val_loss: 0.6941 - val_acc: 0.9779\n",
      "Epoch 4/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.4102 - acc: 0.9739\n",
      "Epoch 00004: val_acc did not improve from 0.97791\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.4102 - acc: 0.9739 - val_loss: 0.1910 - val_acc: 0.9503\n",
      "Epoch 5/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.2107 - acc: 0.9770\n",
      "Epoch 00005: val_acc improved from 0.97791 to 0.97911, saving model to models\\left_leg_model.h5\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.2107 - acc: 0.9770 - val_loss: 0.1642 - val_acc: 0.9791\n",
      "Epoch 6/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.4757 - acc: 0.9751\n",
      "Epoch 00006: val_acc did not improve from 0.97911\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.4750 - acc: 0.9751 - val_loss: 0.1773 - val_acc: 0.9771\n",
      "Epoch 7/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.1520 - acc: 0.9771\n",
      "Epoch 00007: val_acc did not improve from 0.97911\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.1520 - acc: 0.9770 - val_loss: 0.7871 - val_acc: 0.8100\n",
      "Epoch 8/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.5258 - acc: 0.9775\n",
      "Epoch 00008: val_acc did not improve from 0.97911\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.5253 - acc: 0.9775 - val_loss: 0.2258 - val_acc: 0.9771\n",
      "Epoch 9/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.1087 - acc: 0.9795\n",
      "Epoch 00009: val_acc improved from 0.97911 to 0.98010, saving model to models\\left_leg_model.h5\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.1087 - acc: 0.9795 - val_loss: 0.0666 - val_acc: 0.9801\n",
      "Epoch 10/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 1.8784 - acc: 0.9775\n",
      "Epoch 00010: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 1.8892 - acc: 0.9775 - val_loss: 18.4884 - val_acc: 0.9787\n",
      "Epoch 11/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 3.5734 - acc: 0.9766\n",
      "Epoch 00011: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 3.5607 - acc: 0.9765 - val_loss: 0.0876 - val_acc: 0.9785\n",
      "Epoch 12/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9810\n",
      "Epoch 00012: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0984 - acc: 0.9810 - val_loss: 0.1048 - val_acc: 0.9684\n",
      "Epoch 13/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 3.6273 - acc: 0.9731\n",
      "Epoch 00013: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 3.6222 - acc: 0.9731 - val_loss: 0.3009 - val_acc: 0.9781\n",
      "Epoch 14/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.1763 - acc: 0.9784\n",
      "Epoch 00014: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.1761 - acc: 0.9783 - val_loss: 0.1085 - val_acc: 0.9765\n",
      "Epoch 15/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0908 - acc: 0.9810\n",
      "Epoch 00015: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0911 - acc: 0.9809 - val_loss: 0.0946 - val_acc: 0.9763\n",
      "Epoch 16/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0830 - acc: 0.9811\n",
      "Epoch 00016: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0829 - acc: 0.9812 - val_loss: 0.1159 - val_acc: 0.9777\n",
      "Epoch 17/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0747 - acc: 0.9815\n",
      "Epoch 00017: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0747 - acc: 0.9815 - val_loss: 0.0799 - val_acc: 0.9779\n",
      "Epoch 18/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0909 - acc: 0.9810\n",
      "Epoch 00018: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0908 - acc: 0.9810 - val_loss: 0.0822 - val_acc: 0.9775\n",
      "Epoch 19/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9811\n",
      "Epoch 00019: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0737 - acc: 0.9810 - val_loss: 0.0918 - val_acc: 0.9779\n",
      "Epoch 20/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0972 - acc: 0.9806\n",
      "Epoch 00020: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0972 - acc: 0.9806 - val_loss: 0.0749 - val_acc: 0.9785\n",
      "Epoch 21/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0607 - acc: 0.9821\n",
      "Epoch 00021: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0607 - acc: 0.9821 - val_loss: 0.0685 - val_acc: 0.9785\n",
      "Epoch 22/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9816\n",
      "Epoch 00022: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.1099 - acc: 0.9817 - val_loss: 0.0791 - val_acc: 0.9771\n",
      "Epoch 23/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.9683 - acc: 0.9790\n",
      "Epoch 00023: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.9676 - acc: 0.9790 - val_loss: 0.1625 - val_acc: 0.9781\n",
      "Epoch 24/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9793\n",
      "Epoch 00024: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.1386 - acc: 0.9793 - val_loss: 0.0891 - val_acc: 0.9785\n",
      "Epoch 25/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9801\n",
      "Epoch 00025: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.1059 - acc: 0.9801 - val_loss: 0.1868 - val_acc: 0.9787\n",
      "Epoch 26/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0927 - acc: 0.9814\n",
      "Epoch 00026: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0924 - acc: 0.9814 - val_loss: 0.1090 - val_acc: 0.9793\n",
      "Epoch 27/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0733 - acc: 0.9817\n",
      "Epoch 00027: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0733 - acc: 0.9817 - val_loss: 0.0753 - val_acc: 0.9781\n",
      "Epoch 28/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0717 - acc: 0.9821\n",
      "Epoch 00028: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0717 - acc: 0.9821 - val_loss: 0.1028 - val_acc: 0.9787\n",
      "Epoch 29/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0852 - acc: 0.9816\n",
      "Epoch 00029: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0857 - acc: 0.9815 - val_loss: 0.3510 - val_acc: 0.9755\n",
      "Epoch 30/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9819\n",
      "Epoch 00030: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0847 - acc: 0.9819 - val_loss: 0.1104 - val_acc: 0.9777\n",
      "Epoch 31/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.7117 - acc: 0.9799\n",
      "Epoch 00031: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.7087 - acc: 0.9799 - val_loss: 0.1159 - val_acc: 0.9785\n",
      "Epoch 32/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.5034 - acc: 0.9809\n",
      "Epoch 00032: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.5021 - acc: 0.9808 - val_loss: 0.1032 - val_acc: 0.9787\n",
      "Epoch 33/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0998 - acc: 0.9824\n",
      "Epoch 00033: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0998 - acc: 0.9824 - val_loss: 0.1032 - val_acc: 0.9787\n",
      "Epoch 34/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00034: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 35/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00035: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1035 - val_acc: 0.9787\n",
      "Epoch 36/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00036: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1035 - val_acc: 0.9787\n",
      "Epoch 37/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00037: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1033 - val_acc: 0.9787\n",
      "Epoch 38/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00038: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1035 - val_acc: 0.9787\n",
      "Epoch 39/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00039: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1035 - val_acc: 0.9787\n",
      "Epoch 40/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00040: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1033 - val_acc: 0.9787\n",
      "Epoch 41/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00041: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 42/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9825\n",
      "Epoch 00042: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1033 - val_acc: 0.9787\n",
      "Epoch 43/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00043: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 44/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00044: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 45/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00045: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1033 - val_acc: 0.9787\n",
      "Epoch 46/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00046: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1035 - val_acc: 0.9787\n",
      "Epoch 47/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00047: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 48/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00048: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1033 - val_acc: 0.9787\n",
      "Epoch 49/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00049: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1035 - val_acc: 0.9787\n",
      "Epoch 50/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00050: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 51/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.1000 - acc: 0.9822\n",
      "Epoch 00051: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.1001 - acc: 0.9822 - val_loss: 0.1037 - val_acc: 0.9787\n",
      "Epoch 52/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9824\n",
      "Epoch 00052: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0880 - acc: 0.9824 - val_loss: 0.1018 - val_acc: 0.9785\n",
      "Epoch 53/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9822\n",
      "Epoch 00053: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0879 - acc: 0.9822 - val_loss: 0.1036 - val_acc: 0.9787\n",
      "Epoch 54/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00054: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1033 - val_acc: 0.9787\n",
      "Epoch 55/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00055: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0885 - acc: 0.9824 - val_loss: 0.1036 - val_acc: 0.9787\n",
      "Epoch 56/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00056: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 57/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00057: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 58/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00058: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 59/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00059: val_acc did not improve from 0.98010\n",
      "\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 60/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00060: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1035 - val_acc: 0.9787\n",
      "Epoch 61/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00061: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 62/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00062: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 63/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00063: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 64/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00064: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 65/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00065: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 66/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00066: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 67/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00067: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 68/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9825\n",
      "Epoch 00068: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 69/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00069: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 70/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00070: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 71/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00071: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 72/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9823\n",
      "Epoch 00072: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1033 - val_acc: 0.9787\n",
      "Epoch 73/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00073: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1033 - val_acc: 0.9787\n",
      "Epoch 74/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00074: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 75/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00075: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1033 - val_acc: 0.9787\n",
      "Epoch 76/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00076: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 77/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00077: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1035 - val_acc: 0.9787\n",
      "Epoch 78/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00078: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 79/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00079: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1035 - val_acc: 0.9787\n",
      "Epoch 80/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00080: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 81/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00081: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 82/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9823\n",
      "Epoch 00082: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 83/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00083: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 84/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00084: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 85/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00085: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 86/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00086: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 87/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00087: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 88/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00088: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 89/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9823\n",
      "Epoch 00089: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 90/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00090: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 91/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00091: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 92/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00092: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 93/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0880 - acc: 0.9825\n",
      "Epoch 00093: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 94/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00094: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 95/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00095: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 96/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00096: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 97/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00097: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1033 - val_acc: 0.9787\n",
      "Epoch 98/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00098: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 99/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00099: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 100/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00100: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 101/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00101: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1033 - val_acc: 0.9787\n",
      "Epoch 102/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00102: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 103/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00103: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 104/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00104: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 105/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00105: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1035 - val_acc: 0.9787\n",
      "Epoch 106/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00106: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 107/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00107: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1033 - val_acc: 0.9787\n",
      "Epoch 108/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00108: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 109/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00109: val_acc did not improve from 0.98010\n",
      "\n",
      "Epoch 00109: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 110/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00110: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 111/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00111: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 112/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00112: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 113/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00113: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 114/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00114: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 115/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9825\n",
      "Epoch 00115: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 116/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00116: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 117/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00117: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 118/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00118: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 119/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9823\n",
      "Epoch 00119: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 120/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00120: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 121/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00121: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 122/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00122: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 123/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00123: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 124/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00124: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 125/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00125: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 126/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00126: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 127/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9825\n",
      "Epoch 00127: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 128/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00128: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 129/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00129: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 130/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00130: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 131/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9823\n",
      "Epoch 00131: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 132/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00132: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 133/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00133: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 134/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00134: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 135/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00135: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 136/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00136: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 137/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9825\n",
      "Epoch 00137: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 138/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00138: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 139/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00139: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 140/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00140: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 141/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00141: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 142/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00142: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 143/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00143: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 144/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00144: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 145/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00145: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 146/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00146: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 147/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00147: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 148/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00148: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 149/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00149: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 150/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00150: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 151/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00151: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 152/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9825\n",
      "Epoch 00152: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 153/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00153: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 154/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00154: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 155/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00155: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 156/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00156: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 157/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00157: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 158/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00158: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 159/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00159: val_acc did not improve from 0.98010\n",
      "\n",
      "Epoch 00159: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 160/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00160: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 161/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00161: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 162/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00162: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 163/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00163: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 164/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00164: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 165/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00165: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 166/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00166: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 167/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00167: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 168/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00168: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 169/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00169: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 170/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00170: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 171/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00171: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 172/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00172: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 173/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00173: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 174/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00174: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 175/200\n",
      "1411/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00175: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 176/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00176: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 177/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00177: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 178/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00178: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 179/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00179: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 180/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00180: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 181/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00181: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 182/200\n",
      "1409/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00182: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 183/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00183: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 184/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00184: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 185/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9824\n",
      "Epoch 00185: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 186/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0888 - acc: 0.9823\n",
      "Epoch 00186: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 187/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00187: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 188/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00188: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 189/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00189: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 190/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00190: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 191/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9824\n",
      "Epoch 00191: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 192/200\n",
      "1410/1414 [============================>.] - ETA: 0s - loss: 0.0885 - acc: 0.9824\n",
      "Epoch 00192: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 193/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00193: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 194/200\n",
      "1408/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00194: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 10s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 195/200\n",
      "1412/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00195: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 196/200\n",
      "1406/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00196: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 197/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0889 - acc: 0.9823\n",
      "Epoch 00197: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 198/200\n",
      "1413/1414 [============================>.] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00198: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 199/200\n",
      "1414/1414 [==============================] - ETA: 0s - loss: 0.0886 - acc: 0.9824\n",
      "Epoch 00199: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 7ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 200/200\n",
      "1407/1414 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9825\n",
      "Epoch 00200: val_acc did not improve from 0.98010\n",
      "1414/1414 [==============================] - 9s 6ms/step - loss: 0.0886 - acc: 0.9824 - val_loss: 0.1034 - val_acc: 0.9787\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    validation_data=(x_val, y_val),\n",
    "    epochs=200,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint('models/' + part + '_model.h5', monitor='val_acc', verbose=1, save_best_only=True, mode='auto'),\n",
    "        ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=50, verbose=1, mode='auto')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6380dc13-00cd-4acd-a90f-a4af809b24d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, loss_ax = plt.subplots()\n",
    "acc_ax = loss_ax.twinx()\n",
    "\n",
    "loss_ax.plot(history.history['loss'], 'y', label='train loss')\n",
    "loss_ax.plot(history.history['val_loss'], 'r', label='val loss')\n",
    "loss_ax.set_xlabel('epoch')\n",
    "loss_ax.set_ylabel('loss')\n",
    "loss_ax.legend(loc='upper left')\n",
    "\n",
    "acc_ax.plot(history.history['acc'], 'b', label='train acc')\n",
    "acc_ax.plot(history.history['val_acc'], 'g', label='val acc')\n",
    "acc_ax.set_ylabel('accuracy')\n",
    "acc_ax.legend(loc='upper right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e1fb8422-096c-4221-bcee-81c053174c53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[4901,   18],\n",
       "        [  82,   25]],\n",
       "\n",
       "       [[  25,   82],\n",
       "        [  18, 4901]]], dtype=int64)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = load_model('./models/' + part + '_model.h5')\n",
    "\n",
    "y_pred = model.predict(x_val)\n",
    "\n",
    "multilabel_confusion_matrix(np.argmax(y_val, axis=1), np.argmax(y_pred, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "287952a4-25d6-4acb-83c7-d8c5caca30eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir1 = 'C:/Users/BVer/are_you_ok/preprocessing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "48d180f7-7851-40eb-aa9c-d4031f9c25ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.load(file_dir1 + '/kicking/' + 'raw_kicking_kicking_k24.mp4.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "507fb42d-a4e6-4fc6-9285-a0dd046ee8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.load(file_dir1 + '/kicking/' + 'raw_kicking_kicking_k64.mp4.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "534b900c-4da8-49a4-8dca-3e2cd455df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.load(file_dir1 + '/raw_data/' + 'raw_0_slaping_k34.mp4_0_.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "53fd091f-dee0-40d4-8911-314ed5699d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.load(file_dir1 + '/raw_data/' + 'raw_0_slaping_k29.mp4_0_.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4682bd13-71a2-40d1-9865-90340d8e352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = np.load(file_dir1 + '/raw_data/' + 'raw_normal_normal1.mp4.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "407cf8fb-a2b3-45bc-b797-04013385757d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71, 67)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab4dd4b2-c526-42ef-8ae6-6e366fb01bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_raw_part(test):\n",
    "    test = test[:, 54:-1]\n",
    "    seq_length = 30\n",
    "\n",
    "    actions = ['assult', 'normal']\n",
    "    \n",
    "    right_arm_seq = [] #2,3\n",
    "    left_arm_seq = [] #4,5\n",
    "    right_leg_seq = [] #7,8\n",
    "    left_leg_seq = [] #10,11\n",
    "\n",
    "    right_arm_action = 0\n",
    "    left_arm_action = 0\n",
    "    right_leg_action = 0      \n",
    "    left_leg_action = 0\n",
    "\n",
    "    nan_skip_count = 10 #오차 허용 프레임\n",
    "    \n",
    "    right_arm_nan = 0\n",
    "    left_arm_nan = 0\n",
    "    right_leg_nan = 0      \n",
    "    left_leg_nan = 0\n",
    "        \n",
    "    for index, angle_data in enumerate(test):\n",
    "        right_arm_nan = take_not_nan(angle_data[2], angle_data[3], right_arm_seq, right_arm_nan)\n",
    "        left_arm_nan = take_not_nan(angle_data[4], angle_data[5], left_arm_seq, left_arm_nan)\n",
    "        right_leg_nan = take_not_nan(angle_data[7], angle_data[8], right_leg_seq, right_leg_nan)\n",
    "        left_leg_nan = take_not_nan(angle_data[10], angle_data[11], left_leg_seq, left_leg_nan)\n",
    "        \n",
    "        if right_arm_nan == 15:\n",
    "            right_arm_seq = []\n",
    "            right_arm_action = 0\n",
    "        if left_arm_nan == 15:\n",
    "            left_arm_seq = []\n",
    "            left_arm_action = 0\n",
    "        if right_leg_nan == 15:\n",
    "            right_leg_seq = []\n",
    "            right_leg_action = 0\n",
    "        if left_leg_nan == 15:\n",
    "            left_leg_seq = []\n",
    "            left_leg_action = 0\n",
    "        \n",
    "        \n",
    "#         right_arm_action = pred_part(right_arm_seq, right_arm_nan, right_arm_model, right_arm_action, 'right_arm')\n",
    "#         left_arm_action = pred_part(left_arm_seq, left_arm_nan, left_arm_model, left_arm_action, 'left_arm')\n",
    "#         right_leg_action = pred_part(right_leg_seq, right_leg_nan, right_leg_model, right_leg_action, 'right_leg')\n",
    "        left_leg_action = pred_part(left_leg_seq, left_leg_nan, model, left_leg_action, 'left_leg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a20957a0-6c86-4308-83f3-cfff8626a4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_not_nan(key1, key2, part_seq, part_nan):\n",
    "    if not np.isnan(key1) and not np.isnan(key2):\n",
    "        part_seq.append([key1, key2])\n",
    "        return 0\n",
    "    else:\n",
    "        part_nan += 1\n",
    "        if part_nan > 10: #오차 허용 프레임\n",
    "            return 15\n",
    "        else:\n",
    "            return part_nan\n",
    "        \n",
    "def pred_part(part_seq, part_nan, part_model, part_action, part_name):\n",
    "    seq_length = 30\n",
    "    if len(part_seq) > seq_length and part_nan == 0:\n",
    "        input_data = np.expand_dims(np.array(part_seq[-seq_length:], dtype=np.float32), axis=0)\n",
    "        y_pred = part_model.predict(input_data).squeeze()\n",
    "\n",
    "        i_pred = int(np.argmax(y_pred))\n",
    "        conf = y_pred[i_pred]\n",
    "        \n",
    "#         print(conf, i_pred)\n",
    "\n",
    "        if conf > 0.5 and i_pred == 0: #신뢰도\n",
    "            part_action += 1\n",
    "#             print(part_action)\n",
    "            if part_action > 3:\n",
    "                print(part_name, '  detect  assult ')\n",
    "            return part_action\n",
    "        else:\n",
    "            return 0\n",
    "    return part_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6a12416e-0fc2-4899-b7dd-004340ce8b23",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_leg   detect  assult \n",
      "left_leg   detect  assult \n",
      "left_leg   detect  assult \n",
      "left_leg   detect  assult \n",
      "left_leg   detect  assult \n",
      "left_leg   detect  assult \n"
     ]
    }
   ],
   "source": [
    "pred_raw_part(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076042cc-4c62-48ce-9fe4-d0d3224dba22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
